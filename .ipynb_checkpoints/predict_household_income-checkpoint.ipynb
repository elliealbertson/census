{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01bfaa8c",
   "metadata": {},
   "source": [
    "# Predict Median Household Income"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4cc987",
   "metadata": {},
   "source": [
    "This notebook shows how to use supervised machine learning to predict median household income for block groups in California using American Community Survey 2017-2021 5-year data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5996b571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84545eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0b4cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data = pd.read_csv('census_data.csv')\n",
    "census_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029739c0",
   "metadata": {},
   "source": [
    "## Define Label and Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7ee4a6",
   "metadata": {},
   "source": [
    "The label is median household income, which is missing for some block groups. A predictive model could be valuable for filling those missing values.\n",
    "\n",
    "For this analysis, the label and all predictive features are numeric (not categorical)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff927d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['B19013_001E_Estimate_Median_household_income_in_the_past_12_months_(in_2021_inflation-adjusted_dollars)']\n",
    "features = [\n",
    "    'B01002_001E_Estimate_Median_age_--_Total',\n",
    "    'B01001_026E_Estimate_Total_Female_P',\n",
    "    'B03002_003E_Estimate_Total_Not_Hispanic_or_Latino_White_alone_P',\n",
    "    'B03002_004E_Estimate_Total_Not_Hispanic_or_Latino_Black_or_African_American_alone_P',\n",
    "    'B03002_005E_Estimate_Total_Not_Hispanic_or_Latino_American_Indian_and_Alaska_Native_alone_P',\n",
    "    'B03002_006E_Estimate_Total_Not_Hispanic_or_Latino_Asian_alone_P',\n",
    "    'B03002_007E_Estimate_Total_Not_Hispanic_or_Latino_Native_Hawaiian_and_Other_Pacific_Islander_alone_P',\n",
    "    'B03002_008E_Estimate_Total_Not_Hispanic_or_Latino_Some_other_race_alone_P',\n",
    "    'B03002_009E_Estimate_Total_Not_Hispanic_or_Latino_Two_or_more_races_P',\n",
    "    'B03002_012E_Estimate_Total_Hispanic_or_Latino_P',\n",
    "    'B99162_002E_Estimate_Total_Speak_only_English_P',\n",
    "    'C17002_002E_Estimate_Total_Under_.50_P',\n",
    "    'C17002_003E_Estimate_Total_.50_to_.99_P',\n",
    "    'C17002_004E_Estimate_Total_1.00_to_1.24_P',\n",
    "    'C17002_005E_Estimate_Total_1.25_to_1.49_P',\n",
    "    'C17002_006E_Estimate_Total_1.50_to_1.84_P',\n",
    "    'C17002_007E_Estimate_Total_1.85_to_1.99_P',\n",
    "    'C17002_008E_Estimate_Total_2.00_and_over_P',\n",
    "    'B07201_002E_Estimate_Total_Same_house_1_year_ago_P',\n",
    "    'B08301_002E_Estimate_Total_Car,_truck,_or_van_P',\n",
    "    'B08301_010E_Estimate_Total_Public_transportation_(excluding_taxicab)_P',\n",
    "    'B08301_019E_Estimate_Total_Walked_P',\n",
    "    'B08301_021E_Estimate_Total_Worked_from_home_P',\n",
    "    'B25003_003E_Estimate_Total_Renter_occupied_P'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affaf9b4",
   "metadata": {},
   "source": [
    "## Explore the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e54a22a",
   "metadata": {},
   "source": [
    "First, we will look at summary statistics and counts of missing data for the label and features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027e74de",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data[label + features].describe().apply(lambda s: s.apply('{0:.2f}'.format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe071138",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data[census_data[label[0]] == -666666666][label[0]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbba1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data[census_data[features[0]] == -666666666][features[0]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a86a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data[label + features].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37aa11e5",
   "metadata": {},
   "source": [
    "Median income and median age both have missing values indicated by the value '-666666666'. Additionally, the other features have null values constituting a small percent of the data. We will address the missing data before continuing with exploratory data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4cf2cb",
   "metadata": {},
   "source": [
    "For the features, we will replace missing values with the median value of the feature (assuming some features may be skewed, and therefore median may be more of a \"typical\" value than the mean)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be29d9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data_cleaned = census_data.copy()\n",
    "for i in features:\n",
    "    census_data_cleaned[i] = census_data_cleaned[i].fillna(census_data_cleaned[i].median())\n",
    "    census_data_cleaned.loc[census_data_cleaned[i] == -666666666, i] = census_data_cleaned[i].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4cc688",
   "metadata": {},
   "source": [
    "For the label, we will pull out the records with a missing median income for use later as a set of new data to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770eb9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data_cleaned.loc[census_data_cleaned[label[0]] == -666666666, label[0]] = np.nan\n",
    "census_data_new = census_data_cleaned[census_data_cleaned[label[0]].isnull()]\n",
    "census_data_cleaned = census_data_cleaned[census_data_cleaned[label[0]].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ac4e6c",
   "metadata": {},
   "source": [
    "Next, create histograms and examine the distribution of each feature to check for normality and skew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109aafc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in label + features:\n",
    "    fig = plt.figure(figsize=(3, 2))\n",
    "    ax = fig.gca()\n",
    "    feature = census_data_cleaned[i]\n",
    "    feature.hist(bins=100, ax=ax, color='gray')\n",
    "    ax.axvline(feature.mean(), color='blue', linestyle='dashed', linewidth=2)\n",
    "    ax.axvline(feature.median(), color='red', linestyle='dashed', linewidth=2)\n",
    "    ax.set_title(i)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6860da7b",
   "metadata": {},
   "source": [
    "Some features have a close to normal distribution, while others are skewed right or left. Notably, the label appears to be capped around $250,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895d13b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data_cleaned[label[0]][census_data_cleaned[label[0]] >= 249000].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb20118",
   "metadata": {},
   "source": [
    "We will drop observations at the income cap to ensure the model doesn't over-predict the number of block groups at this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc1c7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data_cleaned = census_data_cleaned[census_data_cleaned[label[0]] < 250000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294821f3",
   "metadata": {},
   "source": [
    "Now, create scatterplots to examine potential associations between the features and the label. We will use a random sample of the data to improve visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f34debb",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data_random_1000 = census_data_cleaned.sample(n=1000, random_state=1)\n",
    "for i in features:\n",
    "    fig = plt.figure(figsize=(3, 2))\n",
    "    ax = fig.gca()\n",
    "    feature = census_data_random_1000[i]\n",
    "    lab = census_data_random_1000[label[0]]\n",
    "    correlation = feature.corr(lab)\n",
    "    plt.scatter(x=feature, y=lab, s=2, color='gray')\n",
    "    plt.xlabel(i)\n",
    "    plt.ylabel('Income')\n",
    "    ax.set_title('Income vs. ' + i + ': Correlation = ' + str(correlation.round(2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8574a93",
   "metadata": {},
   "source": [
    "Feature relationships with the label vary. As might be expected, the poverty features have the strongest correlations with median household income."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b63e7f1",
   "metadata": {},
   "source": [
    "## Preprocess the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece7eca1",
   "metadata": {},
   "source": [
    "We will construct a scikit-learn pipeline for simplicity and replicability of preprocessing. To improve model performance, we will apply StandardScaler to scale the numeric features to have a zero-mean and unit variance. We will start by using basic linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8066a202",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82db9a77",
   "metadata": {},
   "source": [
    "Split the data into training and test sets using an 80/20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4ad351",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(census_data_cleaned[features], census_data_cleaned[label], test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c94774",
   "metadata": {},
   "source": [
    "## Run and Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57619eda",
   "metadata": {},
   "source": [
    "Fit the pipeline to the training set to standardize the features and run the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5797b73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c164a6f2",
   "metadata": {},
   "source": [
    "Predict the labels for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cfd659",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd429aa",
   "metadata": {},
   "source": [
    "Calculate model performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a08172",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MSE:\", '{:.0f}'.format(mean_squared_error(y_test, predictions)))\n",
    "print(\"RMSE:\", '{:.0f}'.format(np.sqrt(mean_squared_error(y_test, predictions))))\n",
    "print(\"R-Squared:\", '{:.4f}'.format(r2_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f0c908",
   "metadata": {},
   "source": [
    "Create a scatterplot of the predicted and actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91054af",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, predictions, s=2, color='gray')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Median Household Income Predicted vs. Actuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf0bd9a",
   "metadata": {},
   "source": [
    "The predictions are better than chance, but could potentially be improved. We will run a couple of different models to see if we can improve model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fcb805",
   "metadata": {},
   "source": [
    "## Run and Evaluate Alternative Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3202010c",
   "metadata": {},
   "source": [
    "We will try some ensemble models, which may perform better than basic linear regression because they can model more complex relationships between features and the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1e1f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', RandomForestRegressor())\n",
    "])\n",
    "\n",
    "model = pipeline.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", '{:.0f}'.format(mean_squared_error(y_test, predictions)))\n",
    "print(\"RMSE:\", '{:.0f}'.format(np.sqrt(mean_squared_error(y_test, predictions))))\n",
    "print(\"R-Squared:\", '{:.4f}'.format(r2_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f682bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', GradientBoostingRegressor())\n",
    "])\n",
    "\n",
    "model = pipeline.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", '{:.0f}'.format(mean_squared_error(y_test, predictions)))\n",
    "print(\"RMSE:\", '{:.0f}'.format(np.sqrt(mean_squared_error(y_test, predictions))))\n",
    "print(\"R-Squared:\", '{:.4f}'.format(r2_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64505295",
   "metadata": {},
   "source": [
    "As expected, the other models resulted in better performance. We will proceed with the GradientBoostingRegressor because it had slightly better performance than the RandomForestRegresor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b922c7ad",
   "metadata": {},
   "source": [
    "## Apply the Model to New Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8c6884",
   "metadata": {},
   "source": [
    "Pickle the file to efficiently save it for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41c4754",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './predict_household_income.pkl'\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5a4241",
   "metadata": {},
   "source": [
    "Load the model and the new data to apply it to. Our new dataset will be the records that were missing income data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e78f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = joblib.load(filename)\n",
    "X_new = census_data_new[features].copy()\n",
    "results = loaded_model.predict(X_new)\n",
    "X_new['predicted_income'] = results\n",
    "X_new.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16212fa7",
   "metadata": {},
   "source": [
    "## Useful Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d07157",
   "metadata": {},
   "source": [
    "https://learn.microsoft.com/en-us/training/modules/explore-analyze-data-with-python/5-exercise-visualize-data\n",
    "\n",
    "https://learn.microsoft.com/en-us/training/modules/train-evaluate-regression-models/7-exercise-optimize-save-models\n",
    "\n",
    "https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
